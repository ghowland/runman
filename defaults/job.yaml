# Data we always know
data:
  # Name of the job
  name: Job Name
  
  # Component the job is running against (text based)
  component: Job Component


# Email addresses to always notify.  Not specifically for a job instance, but every job instance.
notify:
  start: []
  success: []
  failure: []


# Users who can see/this job
authorization:
  view: []
  execute: []


# Input data, which will be python string formatted into the "execute" value
input:
  # Input key name
  key:
    # Input value type, example: text, int, decimal
    type: text
    # Type value minimum (numeric)
    min: null
    # Type value maximum (numeric)
    max: null
    # Minimum length (text)
    min length: null
    # Maximum length (text)
    max length: null
    # If set, this acts as a regex against the text (converted if not text) value, to determine it is valid data
    regex validate: null
  
  # Input keys, examples -- These need to be present.  Collect is for the UI to do so.  But this data is also required.
  job_id:
    type: int
  job_instance_id:
    type: int
  component_id:
    type: int
  component:
    type: text
  machine_id:
    type: int
  hostname:
    type: text


# Collect data for this job.  Input to be used by run items
collect:
  - label: Machine
    type: lookup
    datasource: opsdb
    table: machine
    order by: name
    info: Specify the machine to perform this job on.
    
    set:
      machine_id: "%(id)s"
      hostname: "%(name)s"


# Job Run definition
run:
  # Platform specified (ex: linux_redhat, linux_debian, solaris)
  platform:
    # List of Commands: 1st command to execute
    - execute: "command arg1 arg2 arg3"
      # Whether this command can be run without making any changes to the system.
      #NOTE(g): Better to leave false than true if you arent sure.
      idempotent: false
      # Description of what will be changed.  If this is not idempotent, change info is required.  Python formatting allowed.
      change info: null
      
      # Acquire locks.  All locks must be acquired before the job can start.  Any timeouts will abort the job running.
      acquire locks:
        # Only one of these can run at once.
        - key: "%(hostname)s: %(job_id)s"
          # Do not wait for lock, immediately fail.  This is useful for jobs that are scheduled in short periods
          #   (every 5 minutes/seconds).  Another job will begin soon, so waiting for a lock is pointless.
          fail if lock unavailable: true
          # Seconds for timeout if it cannot acquire a lock
          lock timeout: null
      
      # Default input data:
      #   job_id
      #   job_instance_id
      #   component
      #   hostname (machine running the job) - collect:{'type':'lookup', 'datasource':'opsdb', 'table':'machine', 'order_by':'name', 'label':'Machine', 'value':'%(name)s', 'set':{'machine_id':'%(id)s', 'hostname':'%(name)s'}}
      
      # Result Data keys:
      #   exit_code - int
      #   started - timestamp
      #   finished - timestamp
      #   duration - decimal (seconds)
      #   latest_duration - decimal (seconds), this is updated periodically during a job, and gives us variable data
      
      # Process the results: stdout, stderr, file contents, etc.  Performed after execution begins
      process:
        # List of Processing instructions: What to process (ex: stdout, stderr, file)
        - what: stderr
          # If what==file, this specifies the path
          path: null
          # When to process: finished, during
          when: finished
          # If when==during, this is period in seconds to re-process the stdout/stderr/files/etc
          during period: 10.0
          # If specified, this pyformat regex is performed against the "what" specified data
          #   Example: "[%(date)s] %(component)s - %(pid)s - %(message)s", this would extract a date, component, pid and message
          #     key values to be set into the result dictionary, which is tested by the success portion of the process
          pyformat match: null
          # If append==true, then any results found in the match will be appended as a dictionary to the result data,
          #   if append==false, then any keys will be set directly into the result data dict
          append: false
          # If set, this is what gets logged when this is processed.  If when==finished, this will only appear once, and in
          #   sequence of the process items.  If when==during, this will appear each time it runs, also in sequence with other
          #   processing items that are "when==during".  Using Python formatting with input dict overlaid with result dict.
          log: null
          
      
      # List of tests for success factors: Tested in sequence.
      tests:
        # List of success tests.  Key is the result data dict key to use as the test input
        - when: finished
          key: exit_code
          # Function to process key vs. value.  Examples: in, equals, notequals, notin, >, <, <=, >=
          function: in
          # Value for function
          value: [0,]
          # Log message if this test succeeded, using result data dict as python string formatting
          log success: "Exit code successful: %(exit_code)s"
          # Log message if this test failed, using result data dict as python string formatting
          log failure: "Exit code failed: %(exit_code)s"
          # If critical==true, then success testing is stopped as soon as this is found.
          #   If critical==false, then the success testing continues, but the job will still fail with any errors
          critical: false
          # Produces a warning, not critical but something to take note of
          warning: false
        
        # Runs slowly: over 30 seconds
        - when: finished
          key: duration
          function: >
          value: 30.0
          log failure: "Took too longer than 30 seconds: %(duration)s"
          warning: true
        
        # Runs slowly: over 30 seconds -- Currently
        - when: during
          during period: 10.0
          key: current_duration
          function: >
          value: 30.0
          log failure: "Took too longer than 30 seconds: %(duration)s"
          warning: true

